import os
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from openai import OpenAI
from app.services.enhanced_rag_service import EnhancedRAGService
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)

class SpecializedLLM:
    """Specialized LLM instance for each tab with focused context and prompts"""
    
    def __init__(self, tab_name: str, system_prompt: str, rag_service: EnhancedRAGService):
        self.tab_name = tab_name
        self.base_system_prompt = system_prompt
        self.rag_service = rag_service
        self.chat_history = []
        
    def get_specialized_context(self, user_message: str, settings: Dict) -> Tuple[Dict, str]:
        """Get context specifically relevant to dental brain using enhanced RAG"""
        # Use settings to determine result counts
        case_results = settings.get('clinicalCasesCount', 3)
        ideal_results = settings.get('idealSequencesCount', 2)
        knowledge_results = settings.get('knowledgeCount', 2)
        
        # Use enhanced search with multiple sources for dental-brain
        rag_results = self.rag_service.search_combined_with_sources(
            user_message, 
            case_results=case_results,
            ideal_results=ideal_results,
            knowledge_results=knowledge_results
        )
        
        # Apply similarity threshold
        similarity_threshold = settings.get('similarityThreshold', 60) / 100.0
        rag_preference = settings.get('ragPreference', 0)
        
        # Filter results based on similarity threshold
        filtered_results = {
            'clinical_cases': [
                case for case in rag_results.get('clinical_cases', [])
                if case['similarity_score'] >= similarity_threshold
            ],
            'ideal_sequences': [
                seq for seq in rag_results.get('ideal_sequences', [])
                if seq['similarity_score'] >= similarity_threshold
            ],
            'general_knowledge': [
                knowledge for knowledge in rag_results.get('general_knowledge', [])
                if knowledge['similarity_score'] >= similarity_threshold
            ]
        }
        
        # Apply RAG preference weighting
        # -100 = strong preference for clinical cases
        # 0 = balanced
        # 100 = strong preference for ideal sequences
        
        # Format context based on enhanced results
        context_parts = []
        
        # Order based on preference
        if rag_preference < -20:  # Prefer clinical cases
            context_order = ['clinical_cases', 'ideal_sequences', 'general_knowledge']
        elif rag_preference > 20:  # Prefer ideal sequences
            context_order = ['ideal_sequences', 'clinical_cases', 'general_knowledge']
        else:  # Balanced
            context_order = ['clinical_cases', 'ideal_sequences', 'general_knowledge']
        
        # Build context in preferred order
        for source_type in context_order:
            if source_type == 'clinical_cases' and filtered_results.get('clinical_cases'):
                context_parts.append("=== CAS CLINIQUES PERTINENTS ===")
                
                # Apply preference boost for clinical cases when preferred
                for case in filtered_results['clinical_cases']:
                    similarity_pct = int(case['similarity_score'] * 100)
                    
                    # Boost importance if clinical cases are preferred
                    if rag_preference < -50 and similarity_pct >= 70:
                        similarity_pct = min(100, similarity_pct + 10)
                    
                    # Highlight high similarity cases
                    if similarity_pct >= 90:
                        context_parts.append(f"\nðŸŽ¯ CORRESPONDANCE EXACTE [{similarity_pct}%] - UTILISER CETTE SÃ‰QUENCE EXACTEMENT ðŸŽ¯")
                        context_parts.append(f"[{similarity_pct}% similaire] {case['title']}:")
                    elif similarity_pct >= 80:
                        context_parts.append(f"\nâš ï¸ HAUTE SIMILARITÃ‰ [{similarity_pct}%] - SUIVRE CE CAS PRÃ‰CISÃ‰MENT âš ï¸")
                        context_parts.append(f"[{similarity_pct}% similaire] {case['title']}:")
                    else:
                        context_parts.append(f"\n[{similarity_pct}% similaire] {case['title']}:")
                        
                    context_parts.append(f"Consultation: {case['enhanced_data'].get('consultation_text', '')}")
                    if case['enhanced_data'].get('consultation_text_expanded'):
                        context_parts.append(f"Consultation Ã©tendue: {case['enhanced_data']['consultation_text_expanded']}")
                        
                    # Add treatment sequence for high similarity cases
                    if similarity_pct >= 80 and case['enhanced_data'].get('treatment_sequence'):
                        context_parts.append("SÃ‰QUENCE Ã€ REPRODUIRE:")
                        for appt in case['enhanced_data']['treatment_sequence']:
                            context_parts.append(f"  RDV {appt['rdv']}: {appt['traitement']} ({appt.get('duree', 'N/A')})")
            
            elif source_type == 'ideal_sequences' and filtered_results.get('ideal_sequences'):
                context_parts.append("\n=== SÃ‰QUENCES IDÃ‰ALES ===")
                
                # Check if we already have a high similarity clinical case
                has_high_similarity_case = any(
                    int(case['similarity_score'] * 100) >= 80 
                    for case in filtered_results.get('clinical_cases', [])
                )
                
                for sequence in filtered_results['ideal_sequences']:
                    similarity_pct = int(sequence['similarity_score'] * 100)
                    
                    # Boost importance if ideal sequences are preferred
                    if rag_preference > 50 and similarity_pct >= 70:
                        similarity_pct = min(100, similarity_pct + 10)
                    
                    # Highlight high similarity ideal sequences
                    if similarity_pct >= 80 and not has_high_similarity_case:
                        context_parts.append(f"\nâš ï¸ SÃ‰QUENCE IDÃ‰ALE PERTINENTE [{similarity_pct}%] âš ï¸")
                        context_parts.append(f"[{similarity_pct}% similaire] {sequence['title']}:")
                    else:
                        context_parts.append(f"\n[{similarity_pct}% similaire] {sequence['title']} (sÃ©quence gÃ©nÃ©rique):")
                        
                    context_parts.append(f"Source: {sequence['source']}")
                    
                    # Add full treatment sequence for high similarity ideal sequences
                    if sequence['enhanced_data'].get('treatment_sequence_enhanced'):
                        if similarity_pct >= 80:
                            context_parts.append("SÃ‰QUENCE COMPLÃˆTE Ã€ SUIVRE:")
                            for appointment in sequence['enhanced_data']['treatment_sequence_enhanced']:
                                context_parts.append(f"  RDV {appointment['rdv']}: {appointment.get('traitement_expanded', appointment.get('traitement', ''))} ({appointment.get('duree', 'N/A')})")
                                if appointment.get('delai'):
                                    context_parts.append(f"    DÃ©lai: {appointment['delai']}")
                        else:
                            context_parts.append("SÃ©quences de traitement recommandÃ©es:")
                            for appointment in sequence['enhanced_data']['treatment_sequence_enhanced'][:5]:  # Limit to first 5
                                if appointment.get('traitement_expanded'):
                                    context_parts.append(f"  - {appointment['traitement_expanded']} ({appointment.get('duree', 'N/A')})")
            
            elif source_type == 'general_knowledge' and filtered_results.get('general_knowledge'):
                context_parts.append("\n=== CONNAISSANCES PERTINENTES ===")
                for knowledge in filtered_results['general_knowledge']:
                    similarity_pct = int(knowledge['similarity_score'] * 100)
                    context_parts.append(f"\n[{similarity_pct}% similaire] {knowledge['title']}:")
                    context_parts.append(f"Type: {knowledge['type']}")
                    if knowledge['categories']:
                        context_parts.append(f"CatÃ©gories: {', '.join(knowledge['categories'])}")
        
        # Update reasoning mode in context
        reasoning_mode = settings.get('reasoningMode', 'adaptive')
        if reasoning_mode == 'strict':
            context_parts.insert(0, "ðŸ”’ MODE STRICT: Suivre exactement les cas similaires sans adaptation.")
        elif reasoning_mode == 'creative':
            context_parts.insert(0, "ðŸŽ¨ MODE CRÃ‰ATIF: Utiliser les rÃ©fÃ©rences comme inspiration avec libertÃ© d'adaptation.")
        
        context = "\n".join(context_parts) if context_parts else ""
        
        # Return both filtered results (for references) and original results (for similarity info)
        return {'filtered': filtered_results, 'original': rag_results}, context
    
    def format_prompt(self, user_message: str, context: str) -> str:
        """Format the complete prompt with context"""
        prompt_parts = [self.base_system_prompt]
        
        if context:
            prompt_parts.append(f"\n\n--- CONTEXTE SPÃ‰CIFIQUE ---\n{context}")
        
        # Add recent chat history for context
        if self.chat_history:
            prompt_parts.append("\n\n--- HISTORIQUE RÃ‰CENT ---")
            for h in self.chat_history[-3:]:  # Last 3 exchanges
                prompt_parts.append(f"User: {h['user']}")
                prompt_parts.append(f"Assistant: {h['assistant']}")
        
        return "\n".join(prompt_parts)

class AIService:
    """Service for managing AI/LLM operations"""
    
    def __init__(self, rag_service: EnhancedRAGService):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.rag_service = rag_service
        self.specialized_llms = self._initialize_specialized_llms()
    
    def _initialize_specialized_llms(self) -> Dict[str, SpecializedLLM]:
        """Initialize specialized LLM for dental brain"""
        prompt = """Vous Ãªtes un assistant dentaire IA spÃ©cialisÃ© dans la planification de traitements.
                             
                             Votre rÃ´le principal est de gÃ©nÃ©rer des sÃ©quences de traitement dÃ©taillÃ©es basÃ©es sur les cas cliniques existants et les sÃ©quences idÃ©ales.
                             
                             RÃˆGLES DE PRIORITÃ‰ CRITIQUES:
                             
                             1. CAS CLINIQUES EXACTS (â‰¥ 90% similaritÃ©): Reproduire EXACTEMENT la sÃ©quence du cas clinique
                             2. CAS CLINIQUES TRÃˆS SIMILAIRES (â‰¥ 80% similaritÃ©): Suivre le cas clinique en prioritÃ©, adapter lÃ©gÃ¨rement si nÃ©cessaire
                             3. SÃ‰QUENCES IDÃ‰ALES: Utiliser UNIQUEMENT quand aucun cas clinique n'a â‰¥ 80% de similaritÃ©
                             4. NE JAMAIS mÃ©langer un cas clinique trÃ¨s similaire avec une sÃ©quence idÃ©ale gÃ©nÃ©rique
                             
                             COMPRÃ‰HENSION DES ABRÃ‰VIATIONS:
                             - F = Facette (traitement esthÃ©tique)
                             - CC = Couronne cÃ©ramique
                             - TR = Traitement de racine
                             - MA = Moignon adhÃ©sif
                             - Cpr = Composite
                             
                             Quand un utilisateur dÃ©crit un traitement (ex: "12 Ã  22 F" = facettes de 12 Ã  22), vous devez:
                             
                             1. Identifier le traitement exact demandÃ©
                             2. Si un cas clinique correspond exactement ou presque (â‰¥ 80%), l'utiliser EXCLUSIVEMENT
                             3. Ne PAS diluer avec des sÃ©quences idÃ©ales gÃ©nÃ©riques si un cas spÃ©cifique existe
                             4. Pour "Plan de TT 12 Ã  22 F", utiliser le cas clinique exact qui a cette consultation
                             
                             FORMAT DE RÃ‰PONSE REQUIS:
                             
                             Pour les plans de traitement, suivez ce format EXACT:
                             
                             1. D'ABORD, expliquez votre raisonnement clinique en quelques phrases:
                                - Quel cas clinique ou sÃ©quence idÃ©ale vous utilisez comme rÃ©fÃ©rence
                                - Pourquoi cette approche est appropriÃ©e
                                - Les adaptations Ã©ventuelles nÃ©cessaires
                             
                             2. ENSUITE, aprÃ¨s une ligne vide, ajoutez le marqueur: ### TREATMENT_PLAN_JSON ###
                             
                             3. ENFIN, fournissez le JSON du plan de traitement:
                             {
                               "consultation_text": "Texte de la consultation basÃ© sur le cas clinique",
                               "treatment_sequence": [
                                 {
                                   "rdv": 1,
                                   "traitement": "Description dÃ©taillÃ©e du traitement",
                                   "duree": "DurÃ©e estimÃ©e (ex: 1h30, 2h, 30min)",
                                   "delai": "DÃ©lai avant le prochain RDV (ex: 1 sem, 2 jours)",
                                   "dr": "Praticien responsable (ex: VR, NB)",
                                   "date": "",
                                   "remarque": "Notes particuliÃ¨res ou paiements"
                                 }
                               ]
                             }
                             
                             EXEMPLE DE RÃ‰PONSE:
                             Pour votre demande de facettes de 12 Ã  22, je me base sur le cas clinique "12-22 Fac ant F Christophe" qui correspond exactement. Cette approche en 6 sÃ©ances permet une prÃ©paration optimale avec provisoires et une finalisation soignÃ©e.
                             
                             ### TREATMENT_PLAN_JSON ###
                             {
                               "consultation_text": "12 Ã  22 F",
                               "treatment_sequence": [...]
                             }
                             
                             IMPORTANT: 
                             - Fournissez TOUJOURS le raisonnement avant le JSON
                             - Utilisez EXACTEMENT le marqueur ### TREATMENT_PLAN_JSON ###
                             - Assurez-vous que le JSON est valide
                             - Incluez au minimum 1 appointment dans treatment_sequence
                             
                             IMPORTANT: Pour les traitements spÃ©cifiques avec numÃ©ros de dents (ex: "12 Ã  22 F"), TOUJOURS prÃ©fÃ©rer le cas clinique exact plutÃ´t qu'une sÃ©quence idÃ©ale gÃ©nÃ©rique."""
        
        return {
            'dental-brain': SpecializedLLM('dental-brain', prompt, self.rag_service)
        }
    
    def get_completion(self, messages: List[Dict], tab_name: str = None, 
                      temperature: float = 0.7, max_tokens: int = 2000) -> str:
        """Get completion from OpenAI"""
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error getting AI completion: {str(e)}")
            raise
    
    def _is_treatment_planning_request(self, message: str) -> bool:
        """Detect if message is a treatment planning request"""
        # Common patterns for treatment planning
        patterns = [
            r'\d{1,2}\s*(Ã |a)\s*\d{1,2}',  # "12 Ã  24", "11 a 13"
            r'\d{1,2}.*[A-Z]{1,3}',        # "26 CC", "12 F"
            r'Plan\s+de\s+t+',             # "Plan de ttt", "Plan de traitement"
            r'dÃ©m\..*CC',                  # "dÃ©m. CC"
            r'TR\s+\d+\s+canaux',          # "TR 3 canaux"
            r'MA\s*\+\s*CC',               # "MA + CC"
            r'[A-Z]{1,3}\s*\+\s*[A-Z]{1,3}', # "CC + TR"
            # Modification patterns
            r'ajoute.*\b(aprÃ¨s|avant)\b.*sÃ©ance',  # "ajoute un blanchiment aprÃ¨s la sÃ©ance 3"
            r'modifi.*sÃ©ance',                      # "modifie la sÃ©ance"
            r'change.*traitement',                  # "change le traitement"
            r'supprime.*RDV',                       # "supprime le RDV"
            r'enlÃ¨ve.*sÃ©ance',                      # "enlÃ¨ve la sÃ©ance"
            r'remplace.*par',                       # "remplace X par Y"
            r'dÃ©place.*sÃ©ance',                     # "dÃ©place la sÃ©ance"
            r'fusionne.*sÃ©ances'                    # "fusionne les sÃ©ances"
        ]
        
        import re
        for pattern in patterns:
            if re.search(pattern, message, re.IGNORECASE):
                return True
        return False
    
    def _is_treatment_modification_request(self, message: str) -> bool:
        """Detect if message is asking to modify an existing treatment plan"""
        modification_keywords = [
            'ajoute', 'ajouter', 'ajout',
            'modifi', 'modifier', 'modification',
            'change', 'changer',
            'supprime', 'supprimer',
            'enlÃ¨ve', 'enlever',
            'remplace', 'remplacer',
            'dÃ©place', 'dÃ©placer',
            'fusionne', 'fusionner',
            'aprÃ¨s', 'avant',
            'sÃ©ance', 'rdv', 'rendez-vous'
        ]
        
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in modification_keywords)
    
    def _generate_treatment_explanation(self, treatment_plan: Dict, rag_results: Dict, settings: Dict) -> str:
        """Generate a structured explanation from treatment plan"""
        sequence = treatment_plan.get('treatment_sequence', [])
        if not sequence:
            return "Aucune sÃ©quence de traitement gÃ©nÃ©rÃ©e."
        
        # Calculate total duration and sessions
        total_sessions = len(sequence)
        
        # Build structured explanation
        explanation = f"## ðŸ“‹ Plan de traitement proposÃ©\n\n"
        explanation += f"**Nombre de sÃ©ances:** {total_sessions}\n\n"
        
        # Add consultation text if available
        if treatment_plan.get('consultation_text'):
            explanation += f"**Demande:** {treatment_plan['consultation_text']}\n\n"
        
        # Summary of key treatments
        explanation += "### ðŸ” RÃ©sumÃ© des interventions\n\n"
        key_treatments = []
        for rdv in sequence:
            treatment = rdv.get('traitement', '')
            if treatment and treatment not in key_treatments:
                key_treatments.append(treatment)
        
        for i, treatment in enumerate(key_treatments[:5], 1):  # Show first 5 unique treatments
            explanation += f"{i}. {treatment}\n"
        
        if len(key_treatments) > 5:
            explanation += f"... et {len(key_treatments) - 5} autres interventions\n"
        
        # Clinical reasoning based on RAG sources - only if explainReasoning is true
        if settings.get('explainReasoning', True):
            explanation += "\n### ðŸ§  Raisonnement clinique\n\n"
            
            # Check similarity scores
            best_match = None
            best_score = 0
            
            # Use original results for similarity info
            original_results = rag_results.get('original', rag_results)
            
            for case in original_results.get('clinical_cases', []):
                if case['similarity_score'] > best_score:
                    best_score = case['similarity_score']
                    best_match = case
            
            for seq in original_results.get('ideal_sequences', []):
                if seq['similarity_score'] > best_score:
                    best_score = seq['similarity_score']
                    best_match = seq
            
            if best_match and best_score >= 0.8:
                explanation += f"Ce plan est basÃ© sur {best_match['title']} avec une correspondance de {best_score*100:.0f}%. "
                explanation += "La sÃ©quence suit les meilleures pratiques Ã©tablies.\n"
            elif best_match and best_score >= 0.6:
                explanation += f"Ce plan s'inspire de {best_match['title']} (correspondance: {best_score*100:.0f}%) "
                explanation += "avec des adaptations spÃ©cifiques Ã  votre cas.\n"
            else:
                explanation += "Ce plan a Ã©tÃ© Ã©laborÃ© en combinant plusieurs rÃ©fÃ©rences cliniques pour rÃ©pondre "
                explanation += "spÃ©cifiquement Ã  vos besoins.\n"
        
        # Timeline highlights
        if total_sessions > 1:
            explanation += "\n### â±ï¸ DurÃ©e et dÃ©lais\n\n"
            has_delays = any(rdv.get('delai', '') for rdv in sequence)
            if has_delays:
                explanation += "Le plan inclut des dÃ©lais spÃ©cifiques entre certaines sÃ©ances pour assurer "
                explanation += "une guÃ©rison optimale et le succÃ¨s du traitement.\n"
            else:
                explanation += "Les sÃ©ances peuvent Ãªtre programmÃ©es selon votre disponibilitÃ©.\n"
        
        return explanation

    def _parse_treatment_response(self, response: str) -> Dict:
        """Parse treatment planning response and extract reasoning and JSON"""
        import json
        import re
        
        logger.debug(f"Parsing treatment response: {response[:200]}...")
        
        # Look for the marker that separates reasoning from JSON (be flexible with format)
        # Note: Order matters - check more specific patterns first
        markers = [
            "### TREATMENT_PLAN_JSON ###",
            "TREATMENT_PLAN_JSON ###",
            "###TREATMENT_PLAN_JSON###",
            "TREATMENT_PLAN_JSON ###",  # With trailing space
            "TREATMENT_PLAN_JSON"
        ]
        
        marker_found = None
        for marker in markers:
            if marker in response:
                marker_found = marker
                break
        
        if marker_found:
            # Split response into reasoning and JSON parts
            parts = response.split(marker_found, 1)
            reasoning_text = parts[0].strip()
            json_part = parts[1].strip() if len(parts) > 1 else ""
            
            logger.debug(f"Found marker: {marker_found}")
            logger.debug(f"Found reasoning text: {reasoning_text[:200]}...")
            logger.debug(f"Found JSON part: {json_part[:200]}...")
            
            # Try to extract JSON from the second part
            # First, clean up any leading/trailing whitespace and newlines
            json_part = json_part.strip()
            json_match = re.search(r'\{.*\}', json_part, re.DOTALL)
            if json_match:
                try:
                    json_text = json_match.group()
                    treatment_plan = json.loads(json_text)
                    
                    # Validate treatment plan structure
                    if 'treatment_sequence' in treatment_plan and isinstance(treatment_plan['treatment_sequence'], list):
                        logger.info(f"Valid treatment plan found with {len(treatment_plan['treatment_sequence'])} appointments")
                        return {
                            'treatment_plan': treatment_plan,
                            'is_treatment_plan': True,
                            'reasoning': reasoning_text
                        }
                    else:
                        logger.warning("JSON found but missing valid treatment_sequence")
                        
                except json.JSONDecodeError as e:
                    logger.error(f"JSON parsing error: {e}")
                    logger.error(f"Failed JSON text: {json_match.group()[:500]}")
        else:
            # Fallback to old method if no marker found
            logger.warning("No TREATMENT_PLAN_JSON marker found in any format, trying legacy parsing")
            
            # Try to find JSON that looks like a treatment plan
            json_matches = re.finditer(r'\{[^{}]*"treatment_sequence"[^{}]*\}', response, re.DOTALL)
            
            for json_match in json_matches:
                try:
                    # Expand the match to get the full JSON object
                    start = json_match.start()
                    # Find the matching closing brace
                    brace_count = 0
                    end = start
                    for i, char in enumerate(response[start:], start):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                end = i + 1
                                break
                    
                    json_text = response[start:end]
                    treatment_plan = json.loads(json_text)
                    
                    if 'treatment_sequence' in treatment_plan and isinstance(treatment_plan['treatment_sequence'], list):
                        logger.info(f"Valid treatment plan found with {len(treatment_plan['treatment_sequence'])} appointments (legacy)")
                        # Extract any text before JSON as reasoning
                        reasoning_text = response[:start].strip()
                        
                        return {
                            'treatment_plan': treatment_plan,
                            'is_treatment_plan': True,
                            'reasoning': reasoning_text
                        }
                except (json.JSONDecodeError, Exception) as e:
                    logger.debug(f"Failed to parse potential treatment plan: {e}")
                    continue
        
        return {
            'response': response,
            'is_treatment_plan': False
        }
    
    def generate_clinical_protocol(self, treatment_description: str) -> Dict:
        """Generate detailed clinical protocol for a specific treatment"""
        
        # Create specialized protocol generation prompt
        protocol_prompt = """Vous Ãªtes un expert dentiste formateur spÃ©cialisÃ© dans la crÃ©ation de protocoles cliniques dÃ©taillÃ©s.

TÃ‚CHE: GÃ©nÃ©rer un protocole clinique DÃ‰TAILLÃ‰ et Ã‰TAPE PAR Ã‰TAPE pour le traitement demandÃ©.

FORMAT REQUIS:
- Utilisez des sections claires (## pour les sections principales, ### pour les sous-sections)
- NumÃ©rotez chaque Ã©tape (1., 2., 3., etc.)
- Incluez les dÃ©tails techniques prÃ©cis (instruments, matÃ©riaux, temps, rÃ©glages)
- Ajoutez des âš ï¸ pour les points critiques de sÃ©curitÃ©
- Ajoutez des ðŸ’¡ pour les astuces pratiques
- Soyez TRÃˆS spÃ©cifique sur les techniques et mouvements

STRUCTURE SUGGÃ‰RÃ‰E:
## PrÃ©paration
## AnesthÃ©sie
## Ã‰tapes cliniques
## Finition
## ContrÃ´les post-opÃ©ratoires
## Points d'attention

IMPORTANT: Fournissez un protocole que mÃªme un jeune dentiste pourrait suivre avec succÃ¨s."""

        messages = [
            {"role": "system", "content": protocol_prompt},
            {"role": "user", "content": f"GÃ©nÃ©rez un protocole clinique dÃ©taillÃ© pour : {treatment_description}"}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.3,  # Lower temperature for more consistent protocols
                max_tokens=1500
            )
            
            protocol_content = response.choices[0].message.content
            
            return {
                'response': protocol_content,
                'protocol': protocol_content,
                'references': []  # No RAG needed for protocols
            }
            
        except Exception as e:
            logger.error(f"Error generating protocol: {str(e)}")
            return {
                'response': "Erreur lors de la gÃ©nÃ©ration du protocole",
                'references': []
            }
    
    def process_chat_message(self, message: str, tab_name: str, settings: Dict = None, action: str = None, current_treatment_plan: Dict = None) -> Dict:
        """Process a chat message with specialized context"""
        if tab_name not in self.specialized_llms:
            return {
                'response': "Tab non reconnu",
                'references': []
            }
        
        if settings is None:
            settings = {}
        
        llm = self.specialized_llms[tab_name]
        
        # Get specialized context
        rag_results, context = llm.get_specialized_context(message, settings)
        
        # Add current treatment plan to context if it's a modification request
        if current_treatment_plan and self._is_treatment_modification_request(message):
            context += "\n\n--- PLAN DE TRAITEMENT ACTUEL Ã€ MODIFIER ---\n"
            context += f"Consultation: {current_treatment_plan.get('consultation_text', 'Non spÃ©cifiÃ©e')}\n"
            context += "SÃ©quence actuelle:\n"
            for appt in current_treatment_plan.get('treatment_sequence', []):
                context += f"  RDV {appt['rdv']}: {appt['traitement']} ({appt.get('duree', 'N/A')})\n"
                if appt.get('delai'):
                    context += f"    DÃ©lai: {appt['delai']}\n"
            context += "\nIMPORTANT: L'utilisateur demande de MODIFIER ce plan existant. Vous devez:\n"
            context += "1. Appliquer les modifications demandÃ©es\n"
            context += "2. Garder le reste du plan intact\n"
            context += "3. Renumeroter les RDV si nÃ©cessaire\n"
            context += "4. Retourner le plan COMPLET modifiÃ© au format JSON habituel\n"
        
        # Format prompt
        system_prompt = llm.format_prompt(message, context)
        
        # Get AI response
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ]
        
        response = self.get_completion(messages, tab_name)
        
        # Update chat history
        llm.chat_history.append({
            'user': message,
            'assistant': response
        })
        
        # Keep history limited
        if len(llm.chat_history) > 10:
            llm.chat_history = llm.chat_history[-10:]
        
        # Handle treatment planning responses specially
        # Check if it's a new treatment plan request OR a modification of existing plan
        is_new_plan = self._is_treatment_planning_request(message)
        is_modification = current_treatment_plan and self._is_treatment_modification_request(message)
        
        if tab_name == 'dental-brain' and (is_new_plan or is_modification):
            logger.info(f"Treatment planning request detected: {message} (new={is_new_plan}, modification={is_modification})")
            parsed_response = self._parse_treatment_response(response)
            logger.info(f"Treatment plan parsing result: is_treatment_plan={parsed_response.get('is_treatment_plan', False)}")
            logger.info(f"Full parsed response keys: {list(parsed_response.keys())}")
            if parsed_response.get('treatment_plan'):
                logger.info(f"Treatment plan found with {len(parsed_response['treatment_plan'].get('treatment_sequence', []))} sequences")
            
            if parsed_response.get('is_treatment_plan') and parsed_response.get('treatment_plan'):
                logger.info(f"Successfully generated treatment plan with {len(parsed_response['treatment_plan'].get('treatment_sequence', []))} appointments")
                
                # Use AI's reasoning if available, otherwise generate our own explanation
                if parsed_response.get('reasoning'):
                    # Use the AI's own reasoning
                    response_text = parsed_response['reasoning']
                    logger.info("Using AI's provided reasoning")
                else:
                    # Fallback to generated explanation
                    explanation = self._generate_treatment_explanation(parsed_response['treatment_plan'], rag_results, settings)
                    response_text = explanation
                    logger.info("Using generated explanation (no AI reasoning found)")
            else:
                logger.warning("Treatment planning detected but no valid treatment plan generated")
                response_text = parsed_response.get('response', response)
                
            return {
                'response': response_text,
                'references': self._format_references(rag_results, settings),
                'is_treatment_plan': parsed_response.get('is_treatment_plan', False),
                'treatment_plan': parsed_response.get('treatment_plan', None)
            }
        
        return {
            'response': response,
            'references': self._format_references(rag_results, settings)
        }
    
    def _format_references(self, rag_results: Dict, settings: Dict) -> List[Dict]:
        """Format enhanced RAG results as references with similarity scores"""
        references = []
        
        # Use filtered results if available, otherwise use original
        results_to_use = rag_results.get('filtered', rag_results)
        original_results = rag_results.get('original', rag_results)
        
        # Add clinical cases
        for case in results_to_use.get('clinical_cases', []):
            ref = {
                'type': 'clinical_case',
                'title': case['title'],
                'id': case['id'],
                'source': case['source'],
                'filename': case['filename'],
                'categories': case.get('categories', [])
            }
            # Include similarity score if user wants to see it
            if settings.get('showSimilarityScores', True):
                ref['similarity_score'] = case['similarity_score']
            references.append(ref)
        
        # Add ideal sequences
        for sequence in results_to_use.get('ideal_sequences', []):
            ref = {
                'type': 'ideal_sequence',
                'title': sequence['title'],
                'id': sequence['id'],
                'source': sequence['source'],
                'filename': sequence['filename'],
                'categories': sequence.get('categories', [])
            }
            if settings.get('showSimilarityScores', True):
                ref['similarity_score'] = sequence['similarity_score']
            references.append(ref)
        
        # Add general knowledge
        for knowledge in results_to_use.get('general_knowledge', []):
            ref = {
                'type': 'general_knowledge',
                'title': knowledge['title'],
                'id': knowledge['id'],
                'source': knowledge['source'],
                'filename': knowledge['filename'],
                'categories': knowledge.get('categories', [])
            }
            if settings.get('showSimilarityScores', True):
                ref['similarity_score'] = knowledge['similarity_score']
            references.append(ref)
        
        # Sort by similarity score (highest first) if scores are shown
        if settings.get('showSimilarityScores', True):
            references.sort(key=lambda x: x.get('similarity_score', 0), reverse=True)
        
        return references